{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "international-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras.datasets import fashion_mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "marked-graph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "40960/29515 [=========================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 32s 1us/step\n",
      "26435584/26421880 [==============================] - 32s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 6s 1us/step\n",
      "4431872/4422102 [==============================] - 6s 1us/step\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "subsequent-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data\n",
    "X_test, y_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "architectural-california",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "animal-penetration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12b7a25e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[650], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "worth-import",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "greatest-funeral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "optical-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "blond-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   1,   0,   0,  13,  73,   0,   0,   1,\n",
       "         4,   0,   0,   0,   0,   1,   1,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   3,   0,  36, 136, 127,  62,\n",
       "        54,   0,   0,   0,   1,   3,   4,   0,   0,   3,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0, 102, 204,\n",
       "       176, 134, 144, 123,  23,   0,   0,   0,   0,  12,  10,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,  72,\n",
       "        15,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "         0,  69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,\n",
       "        88, 172,  66,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "         1,   1,   0, 200, 232, 232, 233, 229, 223, 223, 215, 213, 164,\n",
       "       127, 123, 196, 229,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 183, 225, 216, 223, 228, 235, 227, 224,\n",
       "       222, 224, 221, 223, 245, 173,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 193, 228, 218, 213, 198, 180,\n",
       "       212, 210, 211, 213, 223, 220, 243, 202,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   1,   3,   0,  12, 219, 220, 212, 218,\n",
       "       192, 169, 227, 208, 218, 224, 212, 226, 197, 209,  52,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99, 244, 222,\n",
       "       220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119, 167,  56,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "       236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "        92,   0,   0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,\n",
       "         0, 237, 226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215,\n",
       "       218, 255,  77,   0,   0,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "        62, 145, 204, 228, 207, 213, 221, 218, 208, 211, 218, 224, 223,\n",
       "       219, 215, 224, 244, 159,   0,   0,   0,   0,   0,  18,  44,  82,\n",
       "       107, 189, 228, 220, 222, 217, 226, 200, 205, 211, 230, 224, 234,\n",
       "       176, 188, 250, 248, 233, 238, 215,   0,   0,  57, 187, 208, 224,\n",
       "       221, 224, 208, 204, 214, 208, 209, 200, 159, 245, 193, 206, 223,\n",
       "       255, 255, 221, 234, 221, 211, 220, 232, 246,   0,   3, 202, 228,\n",
       "       224, 221, 211, 211, 214, 205, 205, 205, 220, 240,  80, 150, 255,\n",
       "       229, 221, 188, 154, 191, 210, 204, 209, 222, 228, 225,   0,  98,\n",
       "       233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217, 241,\n",
       "        65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224, 229,\n",
       "        29,  75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206,\n",
       "       198, 213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220,\n",
       "       221, 230,  67,  48, 203, 183, 194, 213, 197, 185, 190, 194, 192,\n",
       "       202, 214, 219, 221, 220, 236, 225, 216, 199, 206, 186, 181, 177,\n",
       "       172, 181, 205, 206, 115,   0, 122, 219, 193, 179, 171, 183, 196,\n",
       "       204, 210, 213, 207, 211, 210, 200, 196, 194, 191, 195, 191, 198,\n",
       "       192, 176, 156, 167, 177, 210,  92,   0,   0,  74, 189, 212, 191,\n",
       "       175, 172, 175, 181, 185, 188, 189, 188, 193, 198, 204, 209, 210,\n",
       "       210, 211, 188, 188, 194, 192, 216, 170,   0,   2,   0,   0,   0,\n",
       "        66, 200, 222, 237, 239, 242, 246, 243, 244, 221, 220, 193, 191,\n",
       "       179, 182, 182, 181, 176, 166, 168,  99,  58,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-binary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "simple-delivery",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "geological-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "champion-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, kernel_initializer=\"glorot_uniform\", activation='relu'))\n",
    "model.add(Dense(32, kernel_initializer=\"glorot_uniform\", activation='relu'))\n",
    "model.add(Dense(64, kernel_initializer=\"glorot_uniform\", activation='relu'))\n",
    "model.add(Dense(10, kernel_initializer=\"glorot_uniform\", activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "requested-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "emerging-newton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7500/7500 [==============================] - 5s 565us/step - loss: 2.0692 - accuracy: 0.3288\n",
      "Epoch 2/20\n",
      "7500/7500 [==============================] - 4s 568us/step - loss: 1.1796 - accuracy: 0.4960\n",
      "Epoch 3/20\n",
      "7500/7500 [==============================] - 4s 583us/step - loss: 0.9327 - accuracy: 0.6083\n",
      "Epoch 4/20\n",
      "7500/7500 [==============================] - 5s 603us/step - loss: 0.8840 - accuracy: 0.6208\n",
      "Epoch 5/20\n",
      "7500/7500 [==============================] - 5s 601us/step - loss: 0.8744 - accuracy: 0.6270\n",
      "Epoch 6/20\n",
      "7500/7500 [==============================] - 5s 619us/step - loss: 0.8540 - accuracy: 0.6353\n",
      "Epoch 7/20\n",
      "7500/7500 [==============================] - 5s 685us/step - loss: 0.8578 - accuracy: 0.6309\n",
      "Epoch 8/20\n",
      "7500/7500 [==============================] - 5s 656us/step - loss: 0.8517 - accuracy: 0.6296\n",
      "Epoch 9/20\n",
      "7500/7500 [==============================] - 4s 593us/step - loss: 0.8664 - accuracy: 0.6274\n",
      "Epoch 10/20\n",
      "7500/7500 [==============================] - 5s 606us/step - loss: 0.8920 - accuracy: 0.6228\n",
      "Epoch 11/20\n",
      "7500/7500 [==============================] - 5s 630us/step - loss: 0.8384 - accuracy: 0.6402\n",
      "Epoch 12/20\n",
      "7500/7500 [==============================] - 5s 718us/step - loss: 0.8746 - accuracy: 0.6173\n",
      "Epoch 13/20\n",
      "7500/7500 [==============================] - 5s 614us/step - loss: 0.8458 - accuracy: 0.6379\n",
      "Epoch 14/20\n",
      "7500/7500 [==============================] - 5s 609us/step - loss: 0.8384 - accuracy: 0.6380\n",
      "Epoch 15/20\n",
      "7500/7500 [==============================] - 4s 594us/step - loss: 0.8370 - accuracy: 0.6329\n",
      "Epoch 16/20\n",
      "7500/7500 [==============================] - 4s 589us/step - loss: 0.8232 - accuracy: 0.6382\n",
      "Epoch 17/20\n",
      "7500/7500 [==============================] - 5s 647us/step - loss: 0.8351 - accuracy: 0.6374\n",
      "Epoch 18/20\n",
      "1884/7500 [======>.......................] - ETA: 3s - loss: 0.8885 - accuracy: 0.6065"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-ea320f0482ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-ottawa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
